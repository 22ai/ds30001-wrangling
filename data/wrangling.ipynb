{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a87d65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data Wrangling\n",
    "## Foundations of Machine Learning\n",
    "### `! git clone https://www.github.com/DS3001/wrangling`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69db1a1",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "- First: Data are plural, and the singular is datum. Second: If you can't love data at their worst, you don't deserve them at their best.\n",
    "- The data must be **wrangled** or **cleaned** into some form that is amenable to analysis\n",
    "- This can be an exhausting process, and there is no uniquely correct way to do it: choices have consequences\n",
    "- Common problem: Don't confuse a string that corresponds to a variable's name (e.g. `'Age'`), and a variable holding the string that corresponds to a variable's name (e.g. `var='Age'`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab807f2-97c7-4d0b-b8bb-0819ffd763fa",
   "metadata": {},
   "source": [
    "## Replication and Open Science\n",
    "- Before we go on: Never, ever edit the original data *file(s)*. Do not edit and overwrite the file. Never, ever do this.\n",
    "- You never know what will matter later, so always keep the original data files in a safe place.\n",
    "- Document everything you do in a commented script or markdown file so that in the future, you or someone else can **reproduce** the steps you took to clean the data.\n",
    "- **Reproducibility** means that people can take your data and recreate your results on their own. **Replicability** means that people can do your entire project from scratch (experiment, data, analysis) and get similar results.\n",
    "- The biggest threat to science is the inability to reproduce/replicate results, and a lack of transparency in how results were created: It destroys confidence in the entire enterprise, and makes it impossible for us to make progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e3471",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Files Containing Data\n",
    "- These are the most common file formats I am aware of, and what programs or languages created them:\n",
    "| File Format Extension | Likely Source |\n",
    "| :---: | :---:|\n",
    "|.csv | Any |\n",
    "|.Rda, .Rdata | R |\n",
    "|.dat | SAS |\n",
    "|.sav | SPSS |\n",
    "|.dta | Stata |\n",
    "|.mat | MATLAB |\n",
    "|.xls, .xlsx | Excel |\n",
    "|.json | JavaScript Object Notation|\n",
    "\n",
    "- Like most people, I prefer all of my data to be in *comma separated value* or .csv format: The first thing I do with new data is switch them into .csv to ensure that anyone I'm working with can access them\n",
    "- Some file formats are roughly spreadsheets, like .csv or .xls, but a .json or .db file contains database entries that must be parsed\n",
    "- To analyze data, we typically want them in a particular form: A rectangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81890a",
   "metadata": {},
   "source": [
    "## Codebooks\n",
    "- Data come with documentation, which I am going to generically call a *codebook* or a *data dictionary*\n",
    "- The documentation is usually not very good!\n",
    "- It might be a formal codebook, or it might just be the survey itself that respondents filled out, or it might just be the html/javascript code that created the web page that captured the responses\n",
    "- If you don't have a codebook you shouldn't be analyzing the data: You have no clue what it is\n",
    "    - `Employees` might be a `True/False` about whether the firm has any employees at all, or it might be the number of employees it employs, and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ddcdfd-a5d0-4ee8-b954-7c19754fe9dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data\n",
    "- We are typically interested in modelling some kind of phenomenon: defendants, atoms, stock prices, shark attacks, earthquakes, students, cancer, countries, ...\n",
    "- A specific case or instance of the phenomenon is called an **observation**\n",
    "- The observed attributes of a case are called **variables**\n",
    "- The recorded value of a particular attribute for a particular observation is called a **value**\n",
    "- For example, \"What was the bond amount for defendant 1112?\" \"$550\"\n",
    "    - The variable is the bond amount\n",
    "    - The observation is defendant 1112\n",
    "    - The value of the bond for defendant 1112 is 550 dollars\n",
    "    - The data consist of observations of attributes of different defendants in a legal system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ffae0",
   "metadata": {},
   "source": [
    "## Matrices and Data Frames\n",
    "- I am going to call an ordered collection with $N$ elements a \"tuple of length $N$\"; it could be a base Python tuple or a NumPy list, etc.\n",
    "- When we stack $K$ tuples $(x_1, x_2, ..., x_K)$ of length $N$ side by side, we get an $N \\times K$ object called a *matrix*:\n",
    "$$\n",
    "X = \\left[ x_1, x_2, ..., x_K \\right] = \\left[ \\begin{array}{cccc}\n",
    "x_{11} & x_{12} & \\dots  & x_{1K} \\\\\n",
    "x_{21} & x_{22} & \\dots  & x_{2K} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{N1} & x_{N2} & \\dots & x_{NK} \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "- The indices for $x_{ik}$ are $ik=(\\text{row},\\text{column})$, so the tuple $(x_{i1},...,x_{iK})$ is row $i$ and the tuple $(x_{1k}, x_{2k},...,x_{Nk})$ is column $k$\n",
    "- Matrices have many applications throughout mathematics, statistics, and data science, but are the basic model of data\n",
    "- When each row represents an *observation* and each column represents a *variable*, we call the matrix $X$ a *dataframe*\n",
    "- Advanced machine learning makes calculations directly on the dataframe $X$ as a matrix using linear algebra and vector calculus (e.g., $ \\hat{\\beta} = (X'X)^{-1} X'y$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb56f36",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "- Since Python is a general purpose computing language, it does not automatically have built-in functionality to effectively load, clean, and manipulate data\n",
    "- **Pandas** is currently the most popular data-cleaning package for Python: A set of new functions and object classes that expand the base functionality of Python\n",
    "- You load Pandas into your environment using `import pandas as pd`\n",
    "- The `import` keyword tells Python to look for a package named `pandas`, and the `as` keyword says we'd like to use the letters `pd` to refer to the pandas module\n",
    "- The fundamental class object of the Pandas package is the **dataframe**\n",
    "- There's already a package I like better called Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4636679-d446-4c12-93c2-e8d4acf6ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import the numpy package into your workspace\n",
    "import pandas as pd  # Import the pandas package into your workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedb460",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading Data\n",
    "- The publicly available data that happen to be on my desk right now concern pretrial detention of all defendants in Virginia in 2017; the data file and codebook are available in the folder for today's class\n",
    "- To load .csv data, you'll typically use the `.read_csv(filename)` class method:\n",
    "```python\n",
    "df = pd.read_csv('./data/VirginiaPretrialData2017.csv',low_memory=False)\n",
    "```\n",
    "- .csv files load easily on any computer for any language, which is why we generally prefer them. If you have an Excel or Stata or SAS file, it can require some time/effort to get it loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93e559-9a2c-4ce1-9c13-f9f5d4321f5c",
   "metadata": {},
   "source": [
    "## Getting the Justice Data\n",
    "- This is a fairly large dataset: 53MB\n",
    "- GitHub does not want to host files that large for us\n",
    "- We're going to have to get it straight from the source: The Virginia Sentencing Commission\n",
    "- The website where it lives is: http://www.vcsc.virginia.gov/pretrialdataproject2017.html\n",
    "- To bring it into our workspace, we'll just use Pandas to go get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ff8dd-6bb6-4f47-9ada-a22fc85b93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'\n",
    "df = pd.read_csv(url,low_memory=False) # Pandas downloads and loads the .csv file for you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e284f",
   "metadata": {},
   "source": [
    "## Getting Started With Data\n",
    "- The most basic questions are, How many observations? How many variables, and what are they named?\n",
    "- Every Pandas dataframe has a set of class attributes that are useful for looking at:\n",
    "    - `.shape`: The number of rows and columns\n",
    "    - `.columns`: The names of the columns (`print(df.columns.tolist())` will print all of them)\n",
    "    - `.dtypes`: The types of the variables\n",
    "- To get into the data, you have to look at the *codebook* and read both the definitions of the variables and what kinds of values they can take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201a57f-fee2-4ab8-b1f6-9dfdc952c402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./data/VirginiaPretrialData2017.csv',low_memory=False) # Load the data\n",
    "print(df.shape, '\\n') # List the dimensions of df\n",
    "print(df.dtypes, '\\n') # The types of the variables; `object` is a bad sign\n",
    "print(df.columns[1:5], '\\n') # First five column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c043127-e1ff-47ac-918d-69740eeecf1f",
   "metadata": {},
   "source": [
    "## Visually Inspecting the Dataframe (`.head()`, `.iloc[]`, `.loc[]`)\n",
    "- Whenever you load a data set, you should take a look at its actual values; click on the .csv file in the file explorer panel\n",
    "- A nice way to do this is use the Pandas dataframe method, `df.head()`, but if you have a lot of variables, it can be a bit unwieldy\n",
    "- Jupyter has a data file viewer that represents it as a spreadsheet that can be helpful\n",
    "- If you want to pull particular rows or columns, or otherwise slice the dataframe, you can use the **integer locator class method** `df.iloc[x:y,a:b]` for numeric address and **locator class** `df.loc[row_labels, col_labels]` if you know the names of variables and rows that you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c05c1-4f31-42bd-bc2b-2eeebabb089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "print(df.iloc[1:5,1:5],'\\n') # Show the zero-th to fourth rows/zero-th to seventh columns\n",
    "print(df.loc[1:5,('Defendant_Sex','Defendant_Race')],'\\n') # Show rows 1:5 of Sex and Race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bed5df-55bb-4a71-bca2-22d689be45f0",
   "metadata": {},
   "source": [
    "## Renaming and Creating Variables\n",
    "- Variable names are often too verbose: `BondAmountAtInitialContact`, `Defendant_IndigencyStatus`, and `CaseType_MostSerChargeinContactEvent_regardlessofFinalDisp` -- you're going to have to type these things dozens or hundreds of times\n",
    "- To rename a variable, you can use `df = df.rename(columns = {oldName:newName})` (be careful to pass strings)\n",
    "- To create a variable, you supply the new name as a string, as if you are indexing, `df[varName]=expression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554cbb3-28d9-4fac-b4b1-d40ea944fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'BondAmountAtInitialContact':'bond', \n",
    "                    'Defendant_IndigencyStatus':'is_poor',\n",
    "                    'CaseType_MostSerChargeinContactEvent_regardlessofFinalDisp':'case_type',\n",
    "                    'WhetherDefendantWasReleasedPretrial':'released'}) # Rename variables\n",
    "df['age'] = df['Defendant_Age'] # Creating a new variable called age without replacing Defendant_Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af118743",
   "metadata": {},
   "source": [
    "## Exercise (Loading and Renaming)\n",
    "- Load the shark data, `sharks.csv`\n",
    "- What are the dimensions of the data? What are the types of the variables? What variables look interesting?\n",
    "- Use `.head()`, `.iloc[]` and `.loc[]` to take a look at some variables or rows\n",
    "- Rename the `Fatal (Y/N)` to `fatal`\n",
    "- The shark data look bad, but almost *all* real data that haven't already been cleaned look this bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18bbc16-9782-4662-b139-848988e5d785",
   "metadata": {},
   "source": [
    "## Basic Taxomony of Variables\n",
    "- A **numeric variable** takes real number values like -1 or 5.125 and has units, so magnitudes can at least be compared (e.g. Temperature (in Fahrenheit), Salary (in dollars), Weight (thousands of pounds), Counts (numbers of students))\n",
    "- With a **categorical variable**, there are a finite number of distinct categories the variable might take (e.g. Enrolled in College/University or Not, Alive/Dead, Animal Species, Make of a Car)\n",
    "    - There are categorical *variables* that take numeric *values*, but their units are meaningless (e.g. Zip Code, Area Code, NAICS)\n",
    "- There are times where the appropriate thing to do is model a numeric as a categorical (e.g. grade levels in school are ordered...?)\n",
    "- When a categorical variable takes binary values (e.g. alive/dead), we typically represent it with a **dummy variable** which takes the numeric value 0 or 1 (e.g. `alive == 1`, `dead == 0`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05baca-cee7-4027-8fc8-ef9b0fd35e1d",
   "metadata": {},
   "source": [
    "## Unique Values, Frequency Tables, Histograms\n",
    "- Looking at a column of numbers can often be unproductive, especially if there are many observations\n",
    "- The best tools to automate your understanding of a variable are:\n",
    "    - `df[var].unique()`: Provides a list of the unique values occuring for that variable\n",
    "    - `df[var].value_counts()`: Tabulates the number of times each unique value occurs\n",
    "    - `df[var].hist()`: Plots the value counts as a bar graph\n",
    "- `.unique()` is, in particular, extremely useful for learning how dirty the data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0721d3-988d-4e17-b0f9-211f9c42d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['Defendant_Sex'] # Categorical variable example\n",
    "var = 'sex' \n",
    "print(df[var].unique(),'\\n') # 'n' is not listed in the codebook\n",
    "print(df[var].value_counts(), '\\n') # \n",
    "print(df[var].hist(), '\\n') # About 72% of observations are male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff232acc-f62c-4361-a554-aaa13e1f9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'is_poor' # A dummy variable\n",
    "print(df[var].unique(),'\\n') # Notice these gooses have already messed up their coding\n",
    "print(df[var].value_counts(), '\\n') # Look at the 9 and 99: That is awful\n",
    "print(df[var].hist(), '\\n') # What is \"bad\" about this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea94c03-b1cd-460b-a315-8b1aaff80aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'age' # A numeric variable\n",
    "print(df[var].unique(),'\\n') # Do you see some problem values?\n",
    "print(df[var].value_counts(), '\\n') \n",
    "print(df[var].hist(), '\\n') # This does not look very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510d164-1e51-4202-937d-7c2fe4a561c9",
   "metadata": {},
   "source": [
    "## Exercise (Examining the Data)\n",
    "- What type (numeric, categorical, dummy) are each of the variables in the shark data?\n",
    "- Use `.unique()`, `.value_counts()` and `.hist()` to take a look at variables that interest you in the shark data (Type, Activity, Year, Fatal, Age, Country are a good start)\n",
    "- What patterns or features of the data jump out at you?\n",
    "- Which variables are relatively clean? Which are relatively dirty? Which do you think could be salvaged for interesting analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c2510",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "- Data are *missing* if their values are not recorded in the dataset\n",
    "- Data are typically missing in different ways: There might simply be no recorded value at all -- `... , , ...` -- in the data or it might be recorded but as a specific missing value value code like `\"NA\"` or `-999` or `Don't Know` or `Refusal` --- **check the codebook**\n",
    "- We can't really get started on doing interesting things if the data are full of missings: Pandas will just treat the variable as an object\n",
    "- Handling missing data is the most important issue when you clean a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba6ebd",
   "metadata": {},
   "source": [
    "## Why do we care about missing data?\n",
    "- Abraham Wald was a statistician during WWII, working for the United States. They asked him to solve a problem. Planes would come in after a battle, hit from enemy fire:\n",
    "\n",
    "<img src=\"./plane.png\" width='400' height='400' />\n",
    "\n",
    "- Where does additional armor go to improve odds of survival?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd76dc-06da-472c-9798-851288a001c2",
   "metadata": {},
   "source": [
    "## Other Missing Data Examples\n",
    "- Other examples:\n",
    "    - People who get married have higher salaries, on average\n",
    "    - People who drink wine have longer lifespans, on average\n",
    "    - Use of cannabis and psychedelic drugs has been linked to mental illness\n",
    "    - Many places that imposed stricter pandemic protocols had worse outcomes than places that didn't (e.g. NYC vs CVille)\n",
    "- In social science, every interesting problem is fundamentally a missing data issue\n",
    "- \"Correlation does not imply causation\" isn't a vibe or slogan, it's a mathematical reality with quantitative models and tools for measuring and correcting for the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ea97f-6226-4a4b-8eed-e7b5369f7a77",
   "metadata": {},
   "source": [
    "## `nan`'s and Pandas\n",
    "- In Pandas, there are two options for representing missing values\n",
    "    - The default is to treat it as an `np.nan` from the NumPy package: \"Not-a-number\", and its type is `float`\n",
    "    - Pandas can also treat a missing value as a `None`: An empty/null object without a type or value\n",
    "- We want to responsibly deal with the presence of the missing values without making bad choices that interfere with subsequent analysis\n",
    "- You will often have to add the `.nan`s yourself; Pandas brings a lot of empty variable entries in as an empty string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09047859-9149-4b23-a7c2-9d4583651133",
   "metadata": {},
   "source": [
    "## Exercise (Detecting Missing Data)\n",
    "- What is the missing data situation in the shark data? Are some variables particularly good or bad? Are the variables reasonably clean?\n",
    "- Look, in particular, at `Year`, `Age`, `Type`, `Activity`, and `Species`\n",
    "- How did Pandas import the variables? How did it handle the missing values? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107debe-6bbc-4686-8917-dd8aeb7638ee",
   "metadata": {},
   "source": [
    "## Cleaning Numeric Variables [Detailed]\n",
    "- Often, numeric variables include units like dollar signs or separators like commas in their values that need to be cleaned in addition to values that simply aren't recorded: Otherwise, Pandas will drop those values, which can be a big mistake\n",
    "- To clean a numeric variable:\n",
    "    1. Cleaning: Remove symbols like units (e.g. `$`) or separators (e.g. `1,000`) to preserve as much data as possible using `df[var].str.replace(pattern, replacement)`\n",
    "    2. Coercion: Coerce the values to numeric using the Pandas method `pd.to_numeric(var)`\n",
    "    3. Imputation: Often, you'll also want to create a missing value dummy variable using `df[var].isnull()` and **impute** a `value` using `df[var].fillNA(value)` or `df[var].replace(np.nan,value)` to the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6426d26-9c70-44f5-99e0-59999157219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'age'\n",
    "print('Before coercion: \\n', df[var].describe(),'\\n') # The age variable is not read by Pandas as a number\n",
    "df[var].hist(bins=50) # Initial histogram; check out the x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c75756-d6c9-44f1-a0a4-985cbde72995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to coerce a variable to numeric:\n",
    "df[var] = pd.to_numeric(df[var], errors='coerce') # Coerce the variable to numeric\n",
    "\n",
    "# How to create a missing value dummy:\n",
    "df[var+'_nan'] = df[var].isnull() # Equals 1 if missing, 0 if non-null\n",
    "\n",
    "# After coercion:\n",
    "print('After coercion: \\n', df[var].describe(),'\\n') # Describe the numeric variable\n",
    "df[var].hist(bins = 50) # Histogram of the variable values\n",
    "print('Total Missings: \\n', sum(df[var+'_nan']),'\\n') # How many missing values are there?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334694d6-da80-45f3-9a43-6535d06377fc",
   "metadata": {},
   "source": [
    "## Exercise (Numeric Handling)\n",
    "- Clean the `Age` variable for the shark data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6439b99-12a0-4ce0-a0be-4afbb5adcd90",
   "metadata": {},
   "source": [
    "## Cleaning Categorical Variables [Detailed]\n",
    "- To clean a categorical variable,\n",
    "    - Option 1: Replace each type of missing value with a new category that indicates the information abotu why the variable is missing, as appropriate\n",
    "    - Option 2: Replace missings with `.nan`, and create a dummy for each qualitative type of missing value\n",
    "- With the pretrial data, good examples of this are `case_type` and `is_poor`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393f2f4-aa74-474e-a7aa-a310ab5db288",
   "metadata": {},
   "source": [
    "## Multiple Missing Types\n",
    "- Sometimes, data have more than one flavor of missing:\n",
    "\n",
    "<img src=\"./NA_codes.jpg\" width='400' height='400' />\n",
    "\n",
    "- In a case like this, you make sure there's a unique category for each kind of missing that might occur\n",
    "- Why might this matter? Imagine a household survey question about drug use or multiple numerals for a dummy\n",
    "- An example of this is (unintentionally) the `is_poor` variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7db7c-8291-4fef-8c3f-8187492bbe3c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "var = 'case_type'\n",
    "print(df[var].unique(), '\\n') # A Categorical Example\n",
    "df[var] = df[var].replace(' ',np.nan) # Notice the column replacement\n",
    "print(df[var].value_counts(), '\\n')\n",
    "# \n",
    "var = 'is_poor' # A Dummy Example\n",
    "print(df[var].unique(), '\\n')\n",
    "df[var] = df[var].replace( [9,99], np.nan) # Notice the list\n",
    "print(df[var].value_counts()) # A Dummy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ef581-4062-427f-9c64-349e96a5a9b7",
   "metadata": {},
   "source": [
    "## Exercise (Categorical Handling)\n",
    "- Clean the `Type` variable as much as possible\n",
    "- Create a dummy variable (0/1 valued) that indicates the shark attack was fatal, with `np.nan` for values that are missing\n",
    "- Which attacks were provoked? Is \"not provoked\" the same thing as `Unprovoked`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f089c4",
   "metadata": {},
   "source": [
    "## When are the data \"clean\"?\n",
    "- OK, the data are loaded: Now we want to clean them for analysis\n",
    "- For the kinds of analysis we do, the data are *clean* when:\n",
    "  - The data are in a single $N \\times K$ matrix $X$\n",
    "  - Each row $i=1,...,N$ represents a single observation\n",
    "  - The observations are all of the same kind (e.g. entrepreneurs versus companies)\n",
    "  - Each column $k=1,...,K$ represents a variable\n",
    "  - Missing values are appropriately \"handled\" (converted to `.nan` where appropriate or imputed/missing-dummied when appropriate)\n",
    "- We might also want some other things (this updgrades \"clean\" to \"tidy\"):\n",
    "  - The variable names make sense (not \"NewVaCode297ViolentOff_VCCPrefix\")\n",
    "  - \"Unnecessary\" variables are removed\n",
    "  - Dates are converted into numerical values, like decimal date (e.g. 2018.125) or numeric dummies\n",
    "  - If the data are contained in multiple files, you end up with a single file combining all the relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8780a-a216-49cb-916f-eef6d131e32a",
   "metadata": {},
   "source": [
    "## Investigating Missing Data: A Case Study\n",
    "- Handling the `.nan`'s is really just the first step with missing data\n",
    "- For key variables, you want to eliminate as many `.nan`'s as possible through detective work\n",
    "- Let's take a look at the `bond` variable: This is a crucial variable in the justice system, and most of the values are missing\n",
    "- This is an example of a variable with a **long tail** of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cd671-b756-492c-9092-d66468f2f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'bond'\n",
    "df[var] = pd.to_numeric(df[var], errors='coerce') # Coerce the variable to numeric\n",
    "\n",
    "print(df[var].describe(),'\\n') # Describe the numeric variable\n",
    "df[var].hist(bins = 50) # Histogram of the variable values\n",
    "\n",
    "df['bond_NA'] = df[var].isnull() # Create a bond missing dummy; long tail\n",
    "\n",
    "print(sum(df['bond_NA']),'\\n') # How many missing values are there?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321f3f4-33ca-4331-b04f-32c1fd770a9f",
   "metadata": {},
   "source": [
    "## Investigating Missing Data: Cross tabulation\n",
    "- The relationships between variables are important, and we want a quick way of seeing how they relate\n",
    "- *Cross tabulation* is when you break two variables into categories, and enumerate the number in each of the bins\n",
    "- The call in Pandas is `pd.crosstab( df[var1], df[var2] )`\n",
    "- Notice this is a Pandas method (`pd.`) and not a dataframe object method (`df.`)\n",
    "- This is often the first step in determining how variables co-vary with one another, before computing a statistic or using a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217924df-15ff-436b-88b4-688b6a6d7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['is_poor'], df['case_type']) # Notice the use of pd. and not df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780488cd-386f-4b97-8dae-9a5cc903c9b3",
   "metadata": {},
   "source": [
    "## Investigating Missing Data: A Case Study\n",
    "- Let's see if we can explain *why* bond is missing so much using other variables, like whether the person was released pre-trial or the type of bond imposed.\n",
    "- In the codebook, we have (notice, no category 8...):\n",
    "  \n",
    "![Bond Types](bondType.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d77b0d-37d0-4c33-86e0-fd25195d49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bond_NA'] = df['bond'].isnull() \n",
    "print(pd.crosstab(df['bond_NA'],df['PretrialReleaseType1']),'\\n') # Not very illuminating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cebb6f-2d75-4258-bbf9-c4aa0ea3db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(df['bond_NA'],df['BondTypeAtInitialContact']),'\\n') # Aha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19633fe-3f6b-45a0-81c7-97cecff31009",
   "metadata": {},
   "source": [
    "## Replacing Values\n",
    "- So we want to replace certain values of the **bond** depending on values of the **bond type**\n",
    "- There are (at least) two ways to do this:\n",
    "    - Use `df.loc[ condition, var] = value` to replace the value of variable `var` with `value` depending on whether `condition` is true\n",
    "    - Use `df[var].mask(condition,value)` to replace the value of variable `var` with `value` depending on whether `condition` is true\n",
    "- We have a serious dilemma with bond category 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229714d6-af4f-45b7-aafc-fb9a8571d95d",
   "metadata": {},
   "source": [
    "## Logical Operators\n",
    "- Often, we want R to check a complex logical condition for every observation\n",
    "- These are some of the most commonly used operators:\n",
    "| Operator | Meaning |\n",
    "| :---: | :---:|\n",
    "| `and` | and |\n",
    "|`or` | or |\n",
    "|$==$, $!=$ | equivalence, inequivalence |\n",
    "|`<=`,`<` | less-than-equal-to, less-than |\n",
    "| `in`, `not in`| set membership, set non-membership |\n",
    "- For example, we'll want to determine the observations for which `df['is_poor'] == (9 or 99)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44523d49-6143-42c5-bbc3-0dcebd39acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each bond type, replace the missings\n",
    "\n",
    "# df.loc[ df['BondTypeAtInitialContact'] == 9, 'bond'] = np.nan # Missing\n",
    "# df.loc[ df['BondTypeAtInitialContact'] == 7, 'bond'] = np.nan # Unknown\n",
    "\n",
    "df.loc[ df['BondTypeAtInitialContact'] == 6, 'bond'] = 0 # No bond posted\n",
    "df.loc[ df['BondTypeAtInitialContact'] == 5, 'bond'] = 0 # No bond posted\n",
    "df.loc[ df['BondTypeAtInitialContact'] == 4, 'bond'] = 0 # No bond posted\n",
    "\n",
    "df['held_wo_bail'] = (df['BondTypeAtInitialContact'] == 1) # Create a held-without-bail dummy\n",
    "df['bond'].mask(df['BondTypeAtInitialContact'] ==1 , np.nan ) # Held without bail. Nan or Inf?\n",
    "\n",
    "print(df['bond'].hist(), '\\n') \n",
    "print(df['bond'].describe(), '\\n')\n",
    "df['bond_NA'] = df['bond'].isnull() # Update the missing dummy\n",
    "print(pd.crosstab(df['bond_NA'],df['BondTypeAtInitialContact']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe58f3-7504-426d-aec3-da9665e1fa7e",
   "metadata": {},
   "source": [
    "## Investigating Missing Data: A Case Study\n",
    "- Notice how we handled the \"held without bail issue\": There is a lot of nuance here\n",
    "- At this point, I'd drop categories 7 and 9, and leave the missing bond values as \"held without bail\"\n",
    "- You might be thinking, \"He is really into analyzing bonds!\"\n",
    "- Not exactly: Cleaning data sets requires some detective work, that's what we're illustrating\n",
    "- The cleaner your data are, the stronger the *signal* becomes relative to the *noise*, reducing *attenuation* of your findings\n",
    "- It requires your full cognitive attention, or your results will be garbage that makes everyone less informed, knowledgeable, and productive (\"GIGO\")\n",
    "- What are the consequences for society if you do a garbage analysis of bonds and sentencing?\n",
    "- We can't get this deeply into every variable in the data, but we must do it for the key ones for our analysis\n",
    "- So how do we continue cleaning up the `bond` variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41135f-f8ff-48dc-ad59-ae0981cc9083",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "- Cross tabulate the cleaned `Type` and `fatal` variables\n",
    "- Clean the `Type` variable up a bit by creating a new variable and consolidating the values into a smaller number of categories by replacing values\n",
    "- Cross tab your new variable and `fatal`\n",
    "- Are provoked attacks typically fatal? Which types of attack are most likely to be fatal?\n",
    "- What does this mean?\n",
    "- How does this exercise make you feel about sharks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f709c07-127a-48be-b455-25e8572d25bc",
   "metadata": {},
   "source": [
    "## Selecting Subsets of the Observations (Row Filtering)\n",
    "- We often want to focus only on a subset of the observations, like defendants accused of a felony\n",
    "- We can **filter** on a conditional/Boolean statement, selecting the rows that get a 1 and discarding those that get a zero\n",
    "- This creates a new dataframe, focused just on what we're interested in: `df['case_type']=='F'`\n",
    "- For example, in the case of felonies, we can create a new dataframe: `df_felony = df[ df['case_type']=='F' ]`In general, the synattax is\n",
    " `new_df = df[ conditional ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73edbc9-a0ed-4787-af66-d322a689eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['case_type'].value_counts(), '\\n') # How many charges of each type?\n",
    "conditional =  (df['case_type']=='F') # Conditional: The charge is a felony\n",
    "print(conditional.value_counts(), '\\n') # Counts for the conditional variable\n",
    "df_felony = df[ conditional ] # Create new dataset\n",
    "print('Old dataframe: ', df.shape, '\\n', 'New dataframe: ', df_felony.shape) # Dimensions of original and new dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cac16d-14ee-4b8c-8d82-627e4fedd511",
   "metadata": {},
   "source": [
    "## Selecting Subsets of the Variables (Column Filtering)\n",
    "- Suppose you only have a few variables you're actually interested in, or you might not want to release some sensitive data like names or phone numbers\n",
    "- You can use `new_df = df.filter( list )` to keep a specific set of variables in the list `list = [var1, var2, ..., varN]`\n",
    "- You can use `new_df = df.drop( list, axis=1 )` to drop a specific set of variables in the list `list = [var1, var2, ..., varN]`\n",
    "- For example, we might want only the demographic data, `list = ['Defendant_Age', 'Defendant_Sex', 'Defendant_Race']`... or we might want to hide those variables for privacy reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6fdbb-d509-4d7b-8e33-6b6ee24973d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['Defendant_Age', 'Defendant_Sex', 'Defendant_Race']\n",
    "new_df = df.filter(list) # Keep only the variables on the list\n",
    "print( new_df.columns, '\\n', new_df.shape, '\\n')\n",
    "new_df = df.drop(list,axis=1) # Drop only the variables on the list\n",
    "print( new_df.columns, '\\n', new_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880f0dc-cf2f-4f20-8cec-48f50a6eb6df",
   "metadata": {},
   "source": [
    "## Saving Your Cleaned Data\n",
    "- Do not ever overwrite the original data file: Put it aside and save it for reproducibility purposes\n",
    "- The most common format to save data in is `.csv`, and the command is almost the same as the one to read the data in: `df.to_csv('')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b82b29-ae2a-4743-9416-9f480486e7c8",
   "metadata": {},
   "source": [
    "## Exercises (Finishing Up)\n",
    "- The next code chunk cleans a bunch of variables I am interested in from the pretrial data and drops the ones I am not interested in\n",
    "- For the shark data, drop all the columns that are \"Unnamed\"\n",
    "- Save your data as a `.csv` with a new name (not `sharks.csv`, which is the original data file; maybe `sharks_clean.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d3544-f4f7-4576-a1f7-b7949198efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pretrial_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
